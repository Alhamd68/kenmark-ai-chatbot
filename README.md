# ðŸ¤– Website AI Chatbot â€“ Kenmark ITan Solutions

A full-stack AI-powered chatbot built for the official website of **Kenmark ITan Solutions**, designed to answer user queries related to company information, services, FAQs, and general website content using a **retrieval-augmented generation (RAG)** approach.

This project was developed as part of the **NMIMS Intern Technical Assignment** for **Kenmark ITan Solutions**.

---

## ðŸš€ Project Overview

The Website AI Chatbot acts as a **virtual assistant** for Kenmark ITan Solutions.
It retrieves answers from a **structured Excel knowledge base** and generates **contextual, non-hallucinatory AI responses** using a **local LLM (Ollama)**.

The system follows a **production-style architecture** with clear separation between:

* Frontend UI
* Backend APIs
* Knowledge retrieval
* AI response generation

---

## âœ¨ Key Features

### ðŸ”¹ Chatbot Interface

* Floating chatbot widget
* Text-based user input
* AI-generated responses
* Session-based chat history
* Typing indicator for better UX

### ðŸ”¹ Knowledge Management

* Knowledge stored in **Excel (.xlsx)** format
* Categories include:

  * About the company
  * Services
  * Contact information
  * Careers & FAQs
* **Admin upload feature** to update knowledge without code changes

### ðŸ”¹ AI & Safety

* Retrieval-Augmented Generation (RAG)
* Responses strictly grounded in the knowledge base
* Polite fallback for unknown queries
* No hallucinated answers

---

## ðŸ§  System Architecture (High Level)

```
User Query
   â†“
Chat UI (Next.js)
   â†“
Chat API (/api/chat)
   â†“
Knowledge Retrieval (Excel)
   â†“
Prompt Injection
   â†“
Local LLM (Ollama â€“ Phi)
   â†“
AI Response
```

---

## ðŸ“Š Knowledge Source Format

The chatbot supports Excel files with the following structure:

| Category | Question                        | Answer                                                                                               |
| -------- | ------------------------------- | ---------------------------------------------------------------------------------------------------- |
| About    | What is Kenmark ITan Solutions? | Kenmark ITan Solutions is a technology company focused on IT consulting, AI solutions, and training. |
| Services | What services are offered?      | Consulting, AI & ML solutions, software development, and professional training.                      |
| Contact  | How can I contact the company?  | Visit the contact page on kenmarkitan.com                                                            |

> Missing or unknown information is handled gracefully with a polite fallback response.

A sample `knowledge.xlsx` file is included in the repository.

---

## ðŸ§° Tech Stack

### Frontend

* Next.js 16 (App Router)
* TypeScript (TSX)
* Tailwind CSS 4.x

### Backend

* Next.js API Routes
* Excel parsing using **exceljs**

### AI Engine

* **Local LLM using Ollama**
* Model used: **Phi**
* Retrieval-Augmented Generation (RAG)

---

## ðŸ–¥ï¸ Local LLM Note (Important)

This project uses a **local LLM (Ollama)** as recommended in the assignment guidelines.

* Ollama runs locally on the developer machine
* AI responses are generated locally
* The deployed application demonstrates the UI and backend architecture
* Local setup instructions are provided below

This approach ensures:

* No dependency on paid APIs
* Full control over AI behavior
* Compliance with preferred tech stack

---

## â–¶ï¸ How to Run Locally

### 1ï¸âƒ£ Install dependencies

```bash
npm install
```

### 2ï¸âƒ£ Install Ollama

Download from: [https://ollama.com](https://ollama.com)

Pull the model:

```bash
ollama pull phi
```

Verify:

```bash
ollama run phi
```

---

### 3ï¸âƒ£ Start the development server

```bash
npm run dev
```

Open:

```
http://localhost:3000
```

---

## ðŸ” Admin Knowledge Upload

* Admins can upload a new `.xlsx` knowledge file directly from the UI
* The chatbot immediately starts using the updated knowledge
* No server restart required

This enables **easy maintenance and scalability**.

---

## ðŸŒ Deployment

The application UI and backend APIs are deployed on **Vercel**.

ðŸ”— **Live Demo URL:**
*(Paste your Vercel URL here)*

> Note: AI responses require the local Ollama runtime when running locally.

---

## ðŸŒ± Future Improvements

* Database persistence for chat logs (MongoDB + Prisma)
* Website content scraping (optional)
* Chat analytics (most asked questions)
* Authentication for admin upload
* Dark mode UI

---

## ðŸ‘¤ Author

**Alhamd Syed**
B.Tech Computer Engineering
NMIMS University

